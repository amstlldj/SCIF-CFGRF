{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f580abcb-f4c6-418a-a2dd-0afd1d59476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import create_dataset\n",
    "from model.UNet import UNet\n",
    "from utils.engine import RFDiffusionTrainer\n",
    "from utils.tools import train_one_epoch, load_yaml, train_parse_option\n",
    "import torch\n",
    "from utils.callbacks import ModelCheckpoint, set_seed, EarlyStopping\n",
    "from utils.RectifiedFlow import RectifiedFlow\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bcddb4d-5f6b-40fb-907a-6d3c970909e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)  # 设置随机种子为42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9864a90c-7891-4167-8f7e-0422f8c5d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟命令行输入\n",
    "sys.argv = [\n",
    "            'train.py',\n",
    "            \"--trainer\", \"rf\", \n",
    "            \"--model\", \"unet\",\n",
    "            \"--scheduler\", \"ReduceLR\"\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21bf59e-e37e-4a5b-9927-33af07594bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, args):\n",
    "    consume = config[\"consume\"]\n",
    "    if consume:\n",
    "        if args.trainer == 'rf':\n",
    "           cp = torch.load(config[\"rf_consume_path\"])\n",
    "        config = cp[\"config\"]\n",
    "    print(config)\n",
    "\n",
    "    device = torch.device(config[\"device\"])\n",
    "    loader = create_dataset(**config[\"Dataset\"])\n",
    "    start_epoch = 1\n",
    "\n",
    "    if args.model == 'unet':\n",
    "       model = UNet(**config[\"Model\"]).to(device)\n",
    "        \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=1e-4)\n",
    "    if args.trainer == 'rf':\n",
    "       trainer = RFDiffusionTrainer(model).to(device)\n",
    "\n",
    "    if args.trainer == 'rf':\n",
    "       model_checkpoint = ModelCheckpoint(**config[\"RF_Callback\"])\n",
    "\n",
    "    # Add learning rate scheduler\n",
    "    if args.scheduler == 'StepLR':\n",
    "       scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif args.scheduler == 'ReduceLR':\n",
    "       scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1)\n",
    "\n",
    "    # 初始化 EarlyStopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=10)  \n",
    "\n",
    "    if consume:\n",
    "        model.load_state_dict(cp[\"model\"])\n",
    "        optimizer.load_state_dict(cp[\"optimizer\"])\n",
    "        model_checkpoint.load_state_dict(cp[\"model_checkpoint\"])\n",
    "        start_epoch = cp[\"start_epoch\"] + 1\n",
    "\n",
    "    if args.trainer == 'rf':\n",
    "        for epoch in range(start_epoch, config[\"epochs\"] + 1):\n",
    "            loss = train_one_epoch(trainer, loader, optimizer, device, epoch, config[\"epochs\"])\n",
    "            # Step the scheduler every epoch\n",
    "            scheduler.step(loss)\n",
    "            # Save checkpoint\n",
    "            model_checkpoint.step(loss, model=model.state_dict(), config=config,\n",
    "                                  optimizer=optimizer.state_dict(), start_epoch=epoch,\n",
    "                                  model_checkpoint=model_checkpoint.state_dict())\n",
    "            # 检查是否早停\n",
    "            if args.earlystopping == True:\n",
    "               if early_stopping.step(loss):\n",
    "                  print(f\"Early stopping at epoch {epoch}\")\n",
    "                  break\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2bd0321-fcf9-4f67-91c4-2c170635b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': {'in_channels': 3, 'out_channels': 3, 'model_channels': 128, 'attention_resolutions': [2], 'num_res_blocks': 2, 'dropout': 0.1, 'channel_mult': [1, 2, 2, 2], 'conv_resample': True, 'num_heads': 8, 'num_classes': 10, 'image_w': 32, 'image_h': 32}, 'Classifier_Model': {'num_classes': 10}, 'Dataset': {'dataset': 'cwru', 'train': True, 'data_path': './data/cwru/BR1_200_train_set_balance', 'download': False, 'image_size': [32, 32], 'mode': 'RGB', 'suffix': ['png', 'jpg'], 'batch_size': 64, 'shuffle': True, 'drop_last': True, 'pin_memory': True, 'num_workers': 4}, 'Classifier_Dataset_train': {'dataset': 'classifier_train', 'train_data_path': './data/cwru_rf_result/cwru_sampler_br1_5_500epoch', 'image_size': [32, 32], 'mode': 'RGB', 'suffix': ['png', 'jpg'], 'batch_size': 64, 'drop_last': True, 'pin_memory': True, 'num_workers': 4}, 'Classifier_Dataset_test': {'dataset': 'classifier_test', 'test_data_path': './data/cwru/test_set', 'image_size': [32, 32], 'mode': 'RGB', 'suffix': ['png', 'jpg'], 'batch_size': 64, 'drop_last': True, 'pin_memory': True, 'num_workers': 4}, 'ListDataset': {'dataset': 'list', 'data_path': './checkpoint/cwru_rf/match_list.pth', 'batch_size': 1, 'shuffle': False, 'drop_last': True, 'pin_memory': False, 'num_workers': 4}, 'Trainer': {'T': 1000, 'beta': [0.0001, 0.02]}, 'Callback': {'filepath': './checkpoint/cwru_ddpm/cwru_ddpm_br1_5_500epoch.pth', 'save_freq': 1}, 'RF_Callback': {'filepath': './checkpoint/cwru_rf/cwru_rf_br1_200_500epoch_demo.pth', 'save_freq': 1}, 'RF_2_Callback': {'filepath': './checkpoint/cwru_rf_2/cwru_rf_2_br1_500epoch.pth', 'save_freq': 1}, 'Cls_Callback': {'filepath': './checkpoint/cwru_cls/cwru_cls_br1_5_vgg16.pth', 'save_freq': 1}, 'device': 'cuda:0', 'epochs': 10, 'consume': False, 'classifier_consume': False, 'consume_path': './checkpoint/cwru_ddpm/cwru_ddpm_br1_5_500epoch.pth', 'rf_consume_path': './checkpoint/cwru_rf/cwru_rf_br1_5_500epoch.pth', 'classifier_consume_path': './checkpoint/cwru_cls/cwru_cls_br1_5_vgg16.pth', 'lr': 0.0001, 'lr_2': 1e-05, 'lr_cls': 0.0001}\n",
      "Dataset size: 100\n",
      "Classes: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10: 100%|\u001b[38;2;255;146;74m██████████\u001b[0m| 1/1 [00:22<00:00, 22.74s/it, train_loss=0.0324]\n",
      "Epoch: 2/10: 100%|\u001b[38;2;255;146;74m██████████\u001b[0m| 1/1 [00:21<00:00, 21.07s/it, train_loss=0.0243]\n",
      "Epoch: 3/10: 100%|\u001b[38;2;255;146;74m██████████\u001b[0m| 1/1 [00:20<00:00, 20.86s/it, train_loss=0.0204]\n",
      "Epoch: 4/10: 100%|\u001b[38;2;255;146;74m██████████\u001b[0m| 1/1 [00:20<00:00, 20.94s/it, train_loss=0.0185]\n",
      "Epoch: 5/10: 100%|\u001b[38;2;255;146;74m██████████\u001b[0m| 1/1 [00:20<00:00, 20.80s/it, train_loss=0.0172]\n",
      "Epoch: 6/10: 100%|\u001b[38;2;255;146;74m██████████\u001b[0m| 1/1 [00:20<00:00, 20.82s/it, train_loss=0.0163]\n",
      "Epoch: 7/10: 100%|\u001b[38;2;255;146;74m██████████\u001b[0m| 1/1 [00:20<00:00, 20.83s/it, train_loss=0.0157]\n",
      "Epoch: 8/10: 100%|\u001b[38;2;255;146;74m██████████\u001b[0m| 1/1 [00:20<00:00, 20.83s/it, train_loss=0.015]\n",
      "Epoch: 9/10: 100%|\u001b[38;2;255;146;74m██████████\u001b[0m| 1/1 [00:20<00:00, 20.86s/it, train_loss=0.0144]\n",
      "Epoch: 10/10: 100%|\u001b[38;2;255;146;74m██████████\u001b[0m| 1/1 [00:20<00:00, 20.99s/it, train_loss=0.0138]\n"
     ]
    }
   ],
   "source": [
    "args = train_parse_option()\n",
    "config = load_yaml(\"config.yml\", encoding=\"utf-8\")\n",
    "train(config, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3f537-9ef8-4b34-9aa5-2d85b6deffc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c8738-efc9-4e56-b0bb-0db4a36a8053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
